<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Presto Embeddings</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700,300" rel="stylesheet" type="text/css">
    <link rel="icon" href="assets/NASA_Harvest_favicon.png">
    <link rel="stylesheet" type="text/css" rel="noopener" target="_blank" href="main.css">
  </head>
  
  <body>
    <!-- Header -->
    <div id="navbar">
        <a href="https://nasaharvest.github.io/">
            <div id="logo">
                <img src="assets/logo.png"/>
                <div id="logotext">
                <h1>NASA Harvest</h1>
                <h3>Machine Learning</h3>
                </div>
            </div>
        </a>
        <div class="menu">
        <a href="https://nasaharvest.github.io/">About</a>
        <a href="https://nasaharvest.github.io/#sessions">Sessions</a>
        <a href="https://nasaharvest.github.io/#profiles">Team</a>
        </div>
    </div>
    
    <div id="content">
        
        
        <h1 style="text-align: center; margin-block-end: 0">Presto Embeddings for Cropland Mapping</h1>
        <p style="text-align: center;">by Ivan Zvonkov, Gabriel Tseng, Hannah Kerner</p>
        <img src="assets/pipeline.png" alt="Presto Embeddings Pipeline" style="width: 100%;">
        <p>
            <strong>Summary: </strong>Geospatial embeddings offer a novel, efficient and adaptable way to map landscape features.
            We use the Presto model to generate geospatial embeddings from several Earth Observation datasets.
            Our embedding generation pipeline is open source and can be run using Vertex AI and Google Earth Engine.
            We show that geospatial embeddings can be used to map cropland with high accuracy and more efficiently than traditional methods.
        </p>

        <details open>
            <summary>Generating Presto Embeddings</summary>
            <h4>Why generate embeddings?</h4>
            <p>
                Presto geospatial embeddings provide a compressed representation of Earth Observation data, 
                enabling more efficient mapping and analysis. Embeddings are generated by using the Presto encoder
                to compress location information, optical imagery (Sentinel-2), radar imagery (Sentinel-1),  
                climatalogy data (ERA5), and elevation data (SRTM) over the course of a year. 
                Each embedding contains 128 features representing a single 10m<sup>2</sup> pixel on Earth.
                Embeddings can be used in place of raw Earth Observation data for various machine learning tasks,
                such as classification, clustering, and anomaly detection. 
                In order to use embeddings they must first be generated for the time frame and area of interest.
                We provide an open source pipeline to do this using Vertex AI and Google Earth Engine.
            </p>
            <h4>Generating Embeddings</h4>
            <p>
                The embedding generation pipeline consists of two steps:
                <ol>
                    <li>Deploying Presto to Google Cloud Vertex AI in Google Colab<br>
                        <a href="https://colab.research.google.com/github/nasaharvest/presto/blob/main/deploy/1_Presto_to_VertexAI.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></li>
                    <li>Using the ee.Model.fromVertexAi function in Google Earth Engine<br><a href="https://code.earthengine.google.com/1d196e8466506239c4780585c0e28d26">Generating Embeddings GEE Script</a></li>
                </ol>
                In step 1, we package the default Presto model into a TorchServe container.
                The container is deployed to a Google Cloud Vertex AI endpoint, which allows for scalable inference 
                using data from Google Earth Engine.
                <br><br>
                In step 2, we call the Vertex AI endpoint from Google Earth Engine, sending Earth observation data for our 
                time frame and area of interest to the deployed Presto model. Once inference is complete, the embeddings are
                saved as a Earth Engine asset.
                <br><br>
                Once predictions are made, you must <strong>undeploy your model</strong> to stop incurring further charges. 
                This can be done in the Vertex AI console or in the provided colab notebook.

            </p>
            
            <h4>Cost Considerations</h4>
            <p>
                While Google Colab and Google Earth Engine (non-commercial) are free to use, 
                deploying Presto to Vertex AI and running large scale inference incurs cloud costs.
                <br>The current cost formula is: 
                 <strong style="background-color: pink">$5.37-$10.14 / 1000 km<sup>2</sup></strong>
            </p>    
            

            <h4>Case Study: Generating Embeddings for Togo</h4>

            To test our pipeline, we generated embeddings for all of Togo (56,785 km<sup>2</sup>).
            The embedding generation took 16 hours and cost $313.40. The final Togo asset size was 128.8 GB.
            
            <div class='click-zoom'> 
                <label>
                    <input type='checkbox' />
                        <img src='assets/togo_cost.png' alt='Cost of Togo Embeddings' style="width: 100%;">
                </label>
            </div> 
            <div class='click-zoom'> 
                <label>
                    <input type='checkbox' />
                        <img src="assets/togo_stats.png" alt="Asset Size"  style="width: 100%;">
                </label>
            </div> 
            


            </p>
            <h4>Sanity Checking Embeddings</h4>
            <p>
                One way of checking the embeddings is to cluster them and compare to existing land cover maps.


        </details>
        <br>
        <details open>
            <summary>Mapping with Embeddings</summary>
            <p>To do.</p>
        </details>

        <p>This work was supported by the NASA Harvest Consortium.</p>
        
    </div>
     
  </body>
</html>
